"""
File contains functions that are used as utilities during training.

Author: Dominik Macko
"""

from typing import Tuple, Union, Any, List, Optional, Dict

import numpy as np
import pandas as pds
from sklearn.model_selection import PredefinedSplit
from sklearn.metrics import f1_score, cohen_kappa_score
from sklearn.utils.class_weight import compute_class_weight

def build_custom_cvsplitter(train_X: np.array,
                            train_y: np.array, 
                            validation_X: np.array,
                            validation_y: np.array
                           ) -> Tuple[np.array, np.array, PredefinedSplit]:
    """Builds custom crossvalidation splitter for given train and validation datasets.
    
    train_X - training input vectors of shape row x col
    train_y - training labels of shape row x 1
    validation_X - validation input vectors of shape row_valid x col
    validation_y - validation labels of shape row_valid x col
    
    returns (X, y, splitter) where 
        X has shape (row + row_valid) x col
        y has shape (row + row_valid) x 1
    
    note: should be used with for example GridSearchCv or RandomSearchCv with cv=splitter and .fit(X, y)
    
    source of inspiration: http://www.wellformedness.com/blog/using-a-fixed-training-development-test-split-in-sklearn/
    """
    
    X = np.concatenate([train_X, validation_X])
    y = np.concatenate([train_y, validation_y])
    
    fold = np.concatenate([
        # the training data, -1 means it is always in training data
        np.full(train_X.shape[0], -1, dtype=np.int8),
        # the validation data
        np.zeros(validation_X.shape[0], dtype=np.int8)
    ])
    
    return (
        X,
        y,
        PredefinedSplit(fold)
    )

def f1_weighted_loss_flaml(X_test: Union[np.array, pd.DataFrame],
                           y_test: Union[np.array, pd.Series],
                           estimator: Any,
                           labels: Union[np.array, List[str]],
                           X_train: Union[np.array, pd.DataFrame],
                           y_train: Union[np.array, pd.Series],
                           weight_test: Optional[np.array]=None,
                           weight_train: Optional[np.array]=None
                          ) -> Tuple[float, float]:
    """Weighted F1 loss used to train models using FLAML library."""
    
    estimator.fit(X_train, y_train)
    pred_test = estimator.predict(X_test)
    pred_train = estimator.predict(X_train)
    return (
        1 - f1_score(y_test, pred_test, labels=labels, average="weighted", sample_weight=weight_test),
        1 - f1_score(y_train, pred_train, labels=labels, average="weighted", sample_weight=weight_train)
    )

def cohen_kappa_loss_flaml(X_test: Union[np.array, pd.DataFrame],
                           y_test: Union[np.array, pd.Series],
                           estimator: Any,
                           labels: Union[np.array, List[str]],
                           X_train: Union[np.array, pd.DataFrame],
                           y_train: Union[np.array, pd.Series],
                           weight_test: Optional[np.array]=None,
                           weight_train: Optional[np.array]=None
                          ):
    """Weighted F1 loss used to train models using FLAML library."""
    
    estimator.fit(X_train, y_train)
    pred_test = estimator.predict(X_test)
    pred_train = estimator.predict(X_train)
    return (
        1 - cohen_kappa_score(y_test, pred_test, labels=labels, sample_weight=weight_test),
        1 - cohen_kappa_score(y_train, pred_train, labels=labels, sample_weight=weight_train)
    )

def compute_balanced_class_weights(train_y: Union[np.array, pd.Series, List[any]]
                                 ) -> Dict[int, float]:
    """Computes balanced class weight dictionary from train targets.
    
    The key is a index of sorted unique values occuring in train_y.
    """

    unique = sorted(np.unique(train_y))
    weights = compute_class_weight("balanced", classes=unique, y=train_y)
    return {i: weights[i] for i in range(len(unique))}

def compute_lgbm_balanced_class_weights_arrays(train_y: Union[np.array, pd.Series, List[any]],
                                               validation_y: Union[np.array, pd.Series, List[any]]
                                              ) -> Tuple[Union[np.array, List[float]], Union[np.array, List[float]]]:
    """Computes array of balanced class weights for LGBM."""
    
    class_weights = compute_balanced_class_weights(train_y)
    return (
        [class_weights[label] for label in train_y],
        [class_weights[label] for label in validation_y]
    )


