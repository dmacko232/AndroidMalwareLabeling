"""
File contains functions that can be used to train Random Forest.

Author: Dominik Macko
"""

from typing import Dict, Any, Union, Callable, Tuple, Optional, List

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from flaml import AutoML
import optuna

from .generic import train_model, train_randomizedsearchcv_model, train_gridsearchcv_model, train_model_flaml
from .utils import f1_weighted_loss_flaml

def random_forest_best_params_surroundings(best_params: Dict[str, Any]) -> Dict[str, Any]:
    """Get best parameters surroundings for random forest."""
    
    min_samples_split = best_params["min_samples_split"]
    min_samples_leaf = best_params["min_samples_leaf"]
    best_params["min_samples_split"] = [min_samples_split - 1, min_samples_split, min_samples_split + 1]
    best_params["min_samples_leaf"] = [min_samples_leaf - 1, min_samples_leaf, min_samples_leaf + 1]
    return best_params

def train_random_forest(train_X: np.array,
                        train_y: np.array,
                        validation_X: np.array,
                        validation_y: np.array,
                        scoring: Union[str, Callable[[Any, np.array, np.array], int]]="f1_weighted",
                        n_jobs: int=8,
                        verbose: int=3,
                        seed: int=42
                       ) -> Tuple[RandomForestClassifier, pd.DataFrame]:
    """Trains random forest classifier by searching for optimal alpha smoothing term.
    
    train_X - training set features
    train_y - training set targets
    validation_X - validation set features
    validation_y - validation set targets
    scoring - scikit scoring function to use
    n_jobs - threads to use
    seed - seed to use
    verbose - scikit verbose level
    
    returns (Random Forest, history dataframe)
    """
    
    grid = {
        "min_samples_split": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21],
        "min_samples_leaf": [3, 5, 7, 9, 11, 13, 15, 17, 19, 21],
    }
    return train_model(
        RandomForestClassifier(n_jobs=n_jobs, random_state=seed,
                               max_features="sqrt", class_weight="balanced",
                               n_estimators=100),
        train_randomizedsearchcv_model,
        train_gridsearchcv_model,
        grid,
        random_forest_best_params_surroundings,
        train_X,
        train_y,
        validation_X,
        validation_y,
        scoring=scoring,
        n_jobs=n_jobs,
        verbose=verbose,
        seed=seed
    ) 

def train_random_forest_flaml(train_X: Union[np.array, pd.DataFrame], 
                              train_y: Union[np.array, pd.Series], 
                              validation_X: Union[np.array, pd.DataFrame], 
                              validation_y: Union[np.array, pd.Series],
                              seconds_time_budget: int=10 * 60,
                              n_jobs=8,
                              log_file_name: str="rf.log"
                             ) -> RandomForestClassifier:
    """Trains random forest using FLAML library.
    
    train_X - training set features
    train_y - training set targets
    validation_X - validation set features
    validation_y - validation set targets
    metric_name - which metric to use
    seconds_time_budget - maximum time budget in seconds
    n_jobs - threads to use
    log_file_name - name of file to log
    
    returns flaml AutoML model
    """

    settings = {
        "time_budget": seconds_time_budget,
        "metric": f1_weighted_loss_flaml,
        "n_jobs": n_jobs,
        "eval_method": "holdout",
        "task": "classification",
        "log_file_name": log_file_name,
        "estimator_list": ["rf"]
    }
    autorf = train_model_flaml(
        train_X,
        train_y,
        validation_X,
        validation_y,
        settings
    )
    return autorf

class RandomForestObjective:
    """Random Forest Objective used for Optuna library to optimize"""
    
    def __init__(
        self,
        train_X: Union[pd.DataFrame, np.array],
        train_y: Union[pd.Series, np.array],
        validation_X: Union[pd.DataFrame, np.array],
        validation_y: Union[pd.Series, np.array],
        scorer: Callable[[Union[np.array, pd.Series], Union[np.array, pd.Series]], float],
        n_jobs: int=8,
        seed: int=42,
        class_weight: str="balanced",
        n_estimators: int=200
    ):
        """Initializes the objective
        
        train_X - training set features
        train_y - training set targets
        validation_X - validation set features
        validation_y - validation set targets
        scorer - callable used to score performance (maximize)
        n_jobs - threads to use
        seed - random seed to use
        class_weight - class weight passed to RandomFOrestClassifier init
        n_estimators - trees to use
        """

        self.train_X = train_X
        self.train_y = train_y
        self.validation_X = validation_X
        self.validation_y = validation_y
        self.scorer = scorer
        self.n_jobs = n_jobs
        self.seed = seed
        self.class_weight = class_weight
        self.n_estimators = n_estimators
        
    def best_model_callback(self,
                            study: optuna.study.Study,
                            trial: optuna.trial.Trial
                           ) -> None:
        """Callback that can be used to store the best model in the study."""
        
        if study.best_trial.number == trial.number:
            study.set_user_attr(key="best_model", value=trial.user_attrs["model"])
    
    def __call__(self, trial: optuna.trial.Trial) -> float:
        """Calls the objective to optimize it.
        
        trial - Optuna trial
        
        returns the scorer score on validation set
        """
        
        min_samples_split = trial.suggest_int("min_samples_split", 2, 40)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 1, 20)
        rf = RandomForestClassifier(
            n_estimators=self.n_estimators,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=self.seed,
            n_jobs=self.n_jobs,
            class_weight=self.class_weight
        )
        
        rf.fit(self.train_X, self.train_y)
        trial.set_user_attr(key="model", value=rf)
        
        validation_pred = rf.predict(self.validation_X)
        return self.scorer(self.validation_y, validation_pred)

def train_random_forest_optuna(train_X: Union[pd.DataFrame, np.array],
                               train_y: Union[pd.Series, np.array],
                               validation_X: Union[pd.DataFrame, np.array],
                               validation_y: Union[pd.Series, np.array],
                               scorer: Callable[[Union[np.array, pd.Series], Union[np.array, pd.Series]], float],
                               study_name: str="random_forest",
                               n_jobs: int=8,
                               seed: int=42,
                               n_trials: int=100
                              ) -> Tuple[RandomForestClassifier, optuna.study.Study]:
    """Trains Random Forest using Optuna.
    
    train_X - training set features
    train_y - training set targets
    validation_X - validation set features
    validation_y - validation set targets
    scorer - callable that is used to score the performance
    study_name - Optuna study name
    n_jobs - threads to use
    seed - random seed to use
    n_trials - maximum trials
    
    returns (Random FOrest model, Optuna study)
    """
    
    study = optuna.create_study(
        direction="maximize",
        study_name=study_name,
        sampler=optuna.samplers.TPESampler(seed=seed)
    )
    
    objective = RandomForestObjective(
        train_X,
        train_y,
        validation_X,
        validation_y,
        scorer,
        seed=seed,
        class_weight="balanced"
    )
    
    study.optimize(
        objective,
        n_trials=n_trials,
        n_jobs=n_jobs,
        callbacks=[objective.best_model_callback],
        gc_after_trial=True
    )
    
    return (
        study.user_attrs["best_model"],
        study    
    )


